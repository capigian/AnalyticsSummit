{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MTSU Data Science Institute](images/MTDataScienceInstituteHorizontal.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Notebook\n",
    "#### Created by Charlie H. Apigian, PhD.  - Interim Director of the Data Science Institute at MTSU\n",
    "<br>\n",
    "#### Contents\n",
    "- Frame the Business Problem\n",
    "- Import Libraries\n",
    "- Import Data\n",
    "- Explore the Data\n",
    "- Cleanse the Data\n",
    "- Transform the Data\n",
    "- Split the Data\n",
    "- Select and Run the Model\n",
    "- Fine Tune the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXX  What is the Business Problem XXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXXXXX  Import Libraries XXXXXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXXXXXX  Import Data XXXXXXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data and create dataframes and arrays that can then be cleansed, transformed, and split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import requests\n",
    "\n",
    "#url_loandata=\"https://raw.githubusercontent.com/capigian/AnalyticsSummit/master/Apigian_NashAnalyticsPresentation/data/Loan_Data.csv\"\n",
    "\n",
    "#df_loandata_url=pd.read_csv(url_loandata, index_col = 1, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loandata_url.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata = pd.read_csv('data/Loan_Data.csv', index_col = 0, header = 0)\n",
    "df_loandata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_loandata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXXXXX  Explore the Data XXXXXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why explore before cleanse?  Exploring and cleansing may be conducted simultaneously, but you cannot cleanse without looking at the data first\n",
    "\n",
    "https://seaborn.pydata.org/examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.head(25)\n",
    "# index on left side and NaN???"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the data\n",
    "## XXXXXXXXXXXXX\n",
    "### Shows a list of summary statistics - what to look for?\n",
    "- Min and max for outliers\n",
    "- Count to see how many columns have NaN values\n",
    "![PandasSummaryStatistics.png](images/PandasSummaryStatistics.png)\n",
    "https://pandas.pydata.org/pandas-docs/stable/basics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata['annual_inc'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata['annual_inc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata['annual_inc'].kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata[['loan_amnt', 'annual_inc', 'revol_bal', 'total_acc', 'tot_coll_amt']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.term.value_counts() #Should probably encode term as 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata_explore = df_loandata[['loan_amnt', 'emp_length', 'annual_inc', 'revol_bal', 'tot_cur_debt', 'total_credit_rv', 'purpose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_loandata_explore, hue = 'purpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata_explore_num = df_loandata_explore.drop('purpose', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(df_loandata_explore_num.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "ax2 = sns.boxplot(y='loan_amnt', x = 'purpose',  data=df_loandata_explore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 2, figsize=(15, 15), sharex=True)\n",
    "sns.boxplot(y='loan_amnt', x = 'purpose',  data=df_loandata_explore, ax=axes[0,0])\n",
    "sns.boxplot(y='emp_length', x = 'purpose',  data=df_loandata_explore, ax=axes[0,1])\n",
    "sns.boxplot(y='annual_inc', x = 'purpose',  data=df_loandata_explore, ax=axes[1,0])\n",
    "sns.boxplot(y='revol_bal', x = 'purpose',  data=df_loandata_explore, ax=axes[1,1])\n",
    "sns.boxplot(y='tot_cur_debt', x = 'purpose',  data=df_loandata_explore, ax=axes[2,0])\n",
    "sns.boxplot(y='total_credit_rv', x = 'purpose',  data=df_loandata_explore, ax=axes[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXXXXX  Cleanse the  Data XXXXXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill with a specific value\n",
    "\n",
    "- Change all NaN values to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.mths_since_last_delinq.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata['mths_since_last_delinq'] = df_loandata['mths_since_last_delinq'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the mean for total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df_loandata,index=[\"purpose\"], values=[\"total_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = df_loandata['total_acc'].mean()\n",
    "df_loandata['total_acc'] = df_loandata['total_acc'].fillna(mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on with Annual Income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_loandata['annual_inc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata['annual_inc'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata[df_loandata['annual_inc'] >10000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake in entering the annual_inc - forgot to add the decimal places - should be 123,600.00 not 12,360,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.loc[[2968827], [\"annual_inc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.loc[[2968827], [\"annual_inc\"]]=123600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.loc[[2968827], [\"annual_inc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='annual_inc', x = 'purpose',  data=df_loandata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(15, 15), sharex=True)\n",
    "sns.boxplot(y='annual_inc', x = 'purpose',  data=df_loandata, ax=axes[0,0])\n",
    "sns.boxplot(y='revol_bal', x = 'purpose',  data=df_loandata, ax=axes[0,1])\n",
    "sns.boxplot(y='tot_cur_debt', x = 'purpose',  data=df_loandata, ax=axes[1,0])\n",
    "sns.boxplot(y='total_credit_rv', x = 'purpose',  data=df_loandata, ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.drop(df_loandata[df_loandata.annual_inc > 1000000].index, inplace=True)\n",
    "df_loandata.drop(df_loandata[df_loandata.revol_bal > 750000].index, inplace=True)\n",
    "df_loandata.drop(df_loandata[df_loandata.tot_cur_debt > 3000000].index, inplace=True)\n",
    "df_loandata.drop(df_loandata[df_loandata.total_credit_rv > 750000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(15, 15), sharex=True)\n",
    "sns.boxplot(y='annual_inc', x = 'purpose',  data=df_loandata, ax=axes[0,0])\n",
    "sns.boxplot(y='revol_bal', x = 'purpose',  data=df_loandata, ax=axes[0,1])\n",
    "sns.boxplot(y='tot_cur_debt', x = 'purpose',  data=df_loandata, ax=axes[1,0])\n",
    "sns.boxplot(y='total_credit_rv', x = 'purpose',  data=df_loandata, ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='annual_inc', y = 'purpose' ,data=df_loandata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXXXX  Transform the Data XXXXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-coding of categorical data\n",
    "\n",
    "<br>\n",
    "### 3 ways to recode categorical data\n",
    "- **label encoder** - changes categories to integers based on alphabetical order\n",
    "- **hot one encoder** - changes one column of categorical data into several binary (dummy) columns\n",
    "- **use a custom function** for changing categories to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Label using Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.sub_grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata['sub_grade'] = lc.fit_transform(df_loandata['sub_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.sub_grade.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables - Hot one encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_home = pd.get_dummies(df_loandata['home_ownership'], drop_first = False)\n",
    "dummies_purpose = pd.get_dummies(df_loandata['purpose'], drop_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_home.info()\n",
    "dummies_purpose.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata = pd.concat([df_loandata, dummies_home, dummies_purpose], axis = 1)\n",
    "df_loandata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata = df_loandata.drop([\"home_ownership\", \"purpose\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_loandata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create own numerical category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loanBad(d):\n",
    "    if d['loan_status'] == 'Charged Off':\n",
    "        return 1\n",
    "    elif d['loan_status'] == 'In Grace Period':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df_loandata['loan_is_bad'] = df_loandata.apply(loanBad, axis = 1)\n",
    "df_loandata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_loandata['loan_is_bad']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata = df_loandata.drop('loan_status', axis = 1) #this drops the target variable from your original dataset,\n",
    "# axis = 1 refers to dropping a column - where axis = 0 would drop row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a copy of the data as a csv file\n",
    "### Why at this point?\n",
    "- includes target and feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata.to_csv('LoanData_Cleansed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create you Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_loandata.drop('loan_is_bad', axis = 1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!\n",
    "\n",
    "# You have create your X and y datasets.  You are ready to model and analyze.\n",
    " \n",
    "# YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!YAY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXXXXXX  Split the Data XXXXXXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "- StandardScaler\n",
    "    - The StandardScaler assumes your data is normally distributed within each feature and will scale them such that the distribution is now centred around 0, with a standard deviation of 1.\n",
    "    ![alt text](images/StandardScalar.png \"Standard\")\n",
    "- MinMaxScaler\n",
    "    - The MinMaxScaler is the probably the most famous scaling algorithm, and follows the following formula for each feature:\n",
    "    ![alt text](images/MinMaxScalar.png \"MinMax\")\n",
    "    \n",
    "\n",
    "From http://benalexkeen.com/feature-scaling-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_train_sc = pd.DataFrame(X_train_sc, columns=X_train.columns)\n",
    "\n",
    "\n",
    "\n",
    "X_test_sc = scaler.fit_transform(X_test)\n",
    "X_test_sc = pd.DataFrame(X_test_sc, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To scale or not to scale?? Why after the split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 5))\n",
    "\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(X_train['loan_amnt'], ax=ax1)\n",
    "sns.kdeplot(X_train['annual_inc'], ax=ax1)\n",
    "sns.kdeplot(X_train['tot_cur_debt'], ax=ax1)\n",
    "ax2.set_title('After Standard Scaler')\n",
    "sns.kdeplot(X_train_sc['loan_amnt'], ax=ax2)\n",
    "sns.kdeplot(X_train_sc['annual_inc'], ax=ax2)\n",
    "sns.kdeplot(X_train_sc['tot_cur_debt'], ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXX  Select and Run the Model XXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "# Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "using non-scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_names=X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without weights\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X_train, y_train)\n",
    "score = logr.score(X_test, y_test)\n",
    "print(score)\n",
    "print(\"\")\n",
    "log_pred = logr.predict(X_test)\n",
    "print(confusion_matrix(y_test, log_pred))\n",
    "print(\"\")\n",
    "print(classification_report(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# XXXXXXXXXXXXXXXXX  Fine Tune the Model XXXXXXXXXXXXXXXXX\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrsc = LogisticRegression(class_weight = {0:1, 1:3})\n",
    "logrsc.fit(X_train_sc, y_train)\n",
    "score = logrsc.score(X_test_sc, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_pred = logrsc.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, scaled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, scaled_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "![Decision-Tree-Algorithms.png](images/Decision-Tree-Algorithms.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=DecisionTreeClassifier()\n",
    "classifier=classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanpred = classifier.predict(X_test)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, df_loanpred))\n",
    "print(\"\")\n",
    "print(\"classification Report\")\n",
    "print(classification_report(y_test, df_loanpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating decision tree in a file(image)\n",
    "from sklearn import tree\n",
    "from io import StringIO\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = StringIO()\n",
    "tree.export_graphviz(classifier, out_file=out, filled=True,rounded=True)\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(classifier, out_file=dot_data,filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Decision Tree Classifier\n",
    "clf2=DecisionTreeClassifier(max_depth=5, max_leaf_nodes=10)\n",
    "clf2=clf2.fit(X_train,y_train)\n",
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(clf2, out_file=dot_data, feature_names=loan_names, filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = range(1,12)\n",
    "scores = []\n",
    "\n",
    "for d in depth:\n",
    "    classifier=DecisionTreeClassifier(max_depth = d)\n",
    "    classifier=classifier.fit(X_train,y_train)\n",
    "    scores.append(classifier.score(X_test, y_test))\n",
    "    print(\"iteration {} done\".format(d))\n",
    "\n",
    "\n",
    "plt.plot(depth, scores, '-o')\n",
    "plt.xlabel('depth, d')\n",
    "plt.ylabel('scores')\n",
    "plt.xticks(depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=DecisionTreeClassifier(max_depth = 6, max_leaf_nodes=10)\n",
    "clf3=classifier.fit(X_train,y_train)\n",
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(clf3, out_file=dot_data, feature_names=loan_names, filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanpred3 = clf3.predict(X_test)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, df_loanpred3))\n",
    "print(\"\")\n",
    "print(\"classification Report\")\n",
    "print(classification_report(y_test, df_loanpred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fi = pd.DataFrame(classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.DataFrame(list(X.columns))\n",
    "df_feat_imp = pd.concat([dt_fi, names], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_imp.columns = ['Importance', 'Features']\n",
    "df_feat_imp.sort_values('Importance', ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "![Ensemble-Algorithms.png](images/Ensemble-Algorithms.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 90, max_depth = 10)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "score = rf.score(X_test, y_test)\n",
    "print(score)\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 90, max_depth = 10)\n",
    "rf = rf.fit(X_train_sc, y_train)\n",
    "score = rf.score(X_test_sc, y_test)\n",
    "print(score)\n",
    "rf_pred1 = rf.predict(X_test_sc)\n",
    "print(classification_report(y_test, rf_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, rf_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.DataFrame(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([columns, fi], axis = 1)\n",
    "features.columns = ['Feature', 'Importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_values(\"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'classifier': [LogisticRegression()],\n",
    "                 'classifier__penalty': ['l1', 'l2'],\n",
    "                 'classifier__C': np.logspace(0, 4, 10)},\n",
    "                {'classifier': [RandomForestClassifier()],\n",
    "                 'classifier__n_estimators': [10, 100, 1000],\n",
    "                 'classifier__max_features': [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search \n",
    "clf_best = GridSearchCV(pipe, search_space, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search\n",
    "best_model = clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View best model\n",
    "best_model.best_estimator_.get_params()['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy Score\")\n",
    "print(score)\n",
    "best_model_pred = best_model.predict(X_test)\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, best_model_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(classification_report(y_test, best_model_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis\n",
    "![Regression-Algorithms.png](images/Regression-Algorithms.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata_reg = df_loandata[df_loandata['loan_is_bad'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loandata_reg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Simple Regression\n",
    "using annual_inc as predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_loandata_reg.drop(['loan_is_bad', 'loan_amnt'], axis =1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_loandata_reg['loan_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "annual_income = df_loandata_reg[['annual_inc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(annual_income, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = reg.predict(annual_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"annual_inc\", y=\"loan_amnt\", data=df_loandata_reg,\n",
    "            ci=None,  markers = 'o', order=3, hue=\"term\", scatter_kws={\"s\": 50});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x=\"annual_inc\", y=\"loan_amnt\", col=\"term\", hue=\"term\",\n",
    "              data=df_loandata_reg)\n",
    "g = (g.set_axis_labels(\"Annual Income\", \"Loan Amount\")\n",
    "       .set(ylim=(0, 40000))\n",
    "       .fig.subplots_adjust(wspace=.02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an order of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x=\"annual_inc\", y=\"loan_amnt\", order=3, col=\"term\", hue=\"term\",\n",
    "              data=df_loandata_reg)\n",
    "g = (g.set_axis_labels(\"Annual Income\", \"Loan Amount\")\n",
    "       .set(ylim=(0, 40000))\n",
    "       .fig.subplots_adjust(wspace=.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(annual_income, y, color = 'blue')\n",
    "plt.plot(annual_income, predictions, color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(annual_income, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(df_loandata_reg.astype(float).corr(),linewidths=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_train_sc = pd.DataFrame(X_train_sc, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_test_sc = scaler.fit_transform(X_test)\n",
    "X_test_sc = pd.DataFrame(X_test_sc, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune the model to find optimal alpha value for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.1, 0.5, 1, 5, 10, 25, 50, 100]\n",
    "scores = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha = a)\n",
    "    lasso.fit(X_train_sc, y_train)\n",
    "    scores.append(lasso.score(X_test_sc, y_test))\n",
    "    print(\"iteration {} done\".format(a))\n",
    "\n",
    "\n",
    "plt.plot(alphas, scores, '-o')\n",
    "plt.xlabel('alpha, a')\n",
    "plt.ylabel('scores')\n",
    "plt.xticks(alphas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha = 10 provides the best score (somewhat minimally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pred = lasso.predict(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lasso = pd.DataFrame(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.DataFrame(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lasso = pd.concat([df_lasso, names], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lasso.columns = ['Coefficient', 'Feature']\n",
    "df_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune the model to find optimal alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1, 5, 10, 25, 50, 100, 150, 200, 300, 400, 500]\n",
    "scores = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha = a)\n",
    "    ridge.fit(X_train_sc, y_train)\n",
    "    scores.append(ridge.score(X_test_sc, y_test))\n",
    "    print(\"iteration {} done\".format(a))\n",
    "\n",
    "\n",
    "plt.plot(alphas, scores, '-o')\n",
    "plt.xlabel('alpha, a')\n",
    "plt.ylabel('scores')\n",
    "plt.xticks(alphas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_preds = ridge.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ridge = pd.DataFrame(ridge.coef_)\n",
    "\n",
    "names = pd.DataFrame(list(X.columns))\n",
    "\n",
    "df_ridge = pd.concat([df_ridge, names], axis = 1)\n",
    "\n",
    "df_ridge.columns = ['Coefficient', 'Feature']\n",
    "df_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pred = pd.DataFrame(lasso_pred)\n",
    "ridge_pred = pd.DataFrame(ridge_preds)\n",
    "preds = pd.concat([lasso_pred, ridge_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.columns = ['Lasso', 'Ridge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'Lasso', y = 'Ridge', data = preds)\n",
    "plt.ylim(0,40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
